# 虚拟内存

一个系统中的进程是与其他进程共享 CPU 和主存资源的。共享主存会形成一系列的挑战

> [!tip] 
> 
> 随着对 CPU 需求的增长，进程以某种合理的平滑方式慢了下来
> 
> 如果太多的进程需要太多的内存，那么它们中的一些根本就无法运行
> 
> 内存还很容易被破坏。如果某个进程不小心写了另一个进程使用的内存，它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败
> 

为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做 **虚拟内存(Virtual Memory, VM)**

> [!tip] 
> 
> **虚拟内存** 是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它 **为每个进程提供了一个 _大的_、_一致的_ 和 _私有_ 的地址空间**
> 

通过一个很清晰的机制，虚拟内存提供了三个重要的能力

> [!important] 
> 
> + 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存
> 
> + 它为每个进程提供了一致的地址空间，从而简化了内存管理
> 
> + 它保护了每个进程的地址空间不被其他进程破坏
> 

虚拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默地、自动地工作的，不需要应用程序员的任何干涉。理解虚拟内存有如下几个原因

+ **虚拟内存是核心的**：虚拟内存遍及计算机系统的所有层面。理解虚拟内存将帮助你更好地理解系统通常是如何工作的
+ **虚拟内存是强大的**：虚拟内存给予应用程序强大的能力，可以 **创建和销毁内存片**、**将内存片映射到磁盘文件** 的某个部分，以及 **与其他进程共享内存**
+ **虚拟内存是危险的**：每次应用程序引用一个变最、间接引用一个指针，或者调用一个诸如 `malloc` 这样的动态分配程序时，它就会和虚拟内存发生交互。如果虚拟内存使用不当，应用将遇到复杂危险的与内存有关的错误

## 物理和虚拟寻址

计算机系统的主存被组织成一个由 $M$ 个连续的字节大小的单元组成的数组。每字节都有一个唯一的 **物理地址**（Physical Address，PA)。第一个字节的地址为$0$，接下来的字节地址为 $1$，再下一个为 $2$，依此类推

给定这种简单的结构，CPU 访问内存的最自然的方式就是使用物理地址。我们把这种方式称为 **物理寻址**。下图展示了一个物理寻址的示例，该示例的上下文是一条加载指令，它读取从物理地址 $4$ 处开始的 $4$ 字节字

![Pasted image 20241028165151|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989338-3acaf8e1b28049b7ae6a6510adcb5b50.png)


> [!tip] 
> 
> 当 CPU 执行这条加载指令时，会生成一个有效物理地址，通过内存总线，把它传递给主存。主存取出从物理地址 $4$ 处开始的 $4$ 字节字，并将它返回给 CPU，CPU 会将它存放在一个寄存器里
> 

早期的 PC 使用物理寻址，而且诸如数字信号处理器、嵌入式微控制器以及 Cray 超级计算机这样的系统仍然继续使用这种寻址方式。然而，现代处理使用的是一种称为 **虚拟寻址** 的寻址方式，如下图所示

![Pasted image 20241028165315|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989341-5719bef4d64f4bd083698ad23faf640d.png)

使用虚拟寻址，CPU 通过生成一个 **虚拟地址**（Virtual Address，VA) 来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做 **地址翻译**。就像异常处理一样，地址翻译需要 CPU 硬件和操作系统之间的紧密合作。CPU 芯片上叫做 **内存管理单元**（Memory Management Unit, **MMU**) 的专用硬件，利用存放在主存中的 **查询表** 来动态翻译虚拟地址

> [!tip] 地址翻译 
> 
> CPU 生成一个虚拟地址，然后将虚拟地址传送给 MMU，MMU 会使用操作系统维护的查询表动态将虚拟地址翻译为物理地址
> 
> 

## 地址空间


**地址空间**(address space)是一个非负整数地址的有序集合

$$
\{0, 1, 2, \cdots\}
$$

如果地址空间中的整数是连续的，那么我们说它是一个 **线性地址空间**。在一个带虚拟内存的系统中，CPU从一个有 $N＝ 2^n$ 个地址的地址空间中生成虚拟地址，这个地址空间称为**虚拟地址空间**

$$
\{0, 1, \cdots, N-1\}
$$

一个地址空间的大小是由表示最大地址所需要的位数来描述的。

> [!tip] 
> 
> 一个包含 $N=2^n$ 个地址的虚拟地址空间就成为 **$n$ 位地址空间**
>  
> 现代系统通常支持 $32$ 位或者 $64$ 位虚拟地址空间
> 

一个系统还有一个 **物理地址空间**，对应于系统中物理内存的 $M$ 个字节

$$
\{0, 1, \cdots, M-1\}
$$

注意，这里 $M$ 不要求是 $2$ 的幕，但是为了简化讨论，我们假设 $M=2^m$


地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）。一旦认识到了这种区别，那么我们就可以将其推广，**允许每个数据对象有多个独立的地址**，其中 **每个地址都选自一个不同的地址空间**

> [!tip] 虚拟内存的基本思想：允许每个数据对象有多个独立的地址，其中每个地址都从不同的地址空间中选择
> 
> 主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址
> 

## 虚拟内存作为缓存工具

概念上而言，**虚拟内存** 被组织为一个由 **存放在磁盘上 的 $N$ 个连续的字节大小的单元组成的 _数组_**。每字节都有一个唯一的 **虚拟地址**，作为到数组的 **索引**。**磁盘上数组的内容被缓存在主存中**。和存储器层次结构中其他缓存一样，**磁盘（较低层）上的数据被分割成 _块_**，这些块作为 **磁盘和主存(较高层）之间的传输单元**

虚拟内存系统通过将虚拟内存分割为称为 **虚拟页**（Virtual Page，VP) 的大小固定的块来处理这个问题。每个虚拟页的大小为 $P = 2^p$ 字节。类似地，物理内存被分割为 **物理页**（Physical Page，PP)，大小也为 $P$ 字节（物理页也被称为 **页帧**（page frame))

> [!tip] 数据块
> 
> 磁盘上的数据被分成 **块**，块作为磁盘和主存之间的传输单元
> 

在任意时刻，虚拟页面的集合都分为三个不相交的子集

| 虚拟页面类型 | 描述                            |
| :----- | :---------------------------- |
| 未分配的   | VM 系统还未分配的页，没有任何数据，因此不占任何磁盘空间 |
| 缓存的    | 已缓存在物理内存中的已分配页                |
| 未缓存的   | 未缓存在物理内存中的已分配页                |

下图展示了一个有 $8$ 个虚拟页的小虚拟内存。虚拟页 $0$ 和 $3$ 还没有被分配，因此在磁盘上还不存在。虚拟页 $1,4,6$ 被缓存在物理内存中。虚拟页 $2,5,7$ 已经被分配，但是当前并未缓存在主内存中

![Pasted image 20241028205612|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989343-29ed6c90f19243f4a7eb2d2d69fd1bec.png)

### DRAM 缓存的组织结构

为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语 **SRAM 缓存** 来表示位于 CPU 和主存之间的 L1，L2 和 L3 高速缓存，并且用术语 **DRAM 缓存** 来表示 **虚拟内存系统的缓存**，它在主存中缓存虚拟页

> [!tip] 不同的缓存概念
> 
> + SRAM 缓存：CPU 和 主存之间的高速缓存
> + DRAM 缓存：虚拟内存系统的缓存，在主存中缓存虚拟页
> 
> 

在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。回想一下，DRAM 比 SRAM 要慢大约 $10$ 倍，而磁盘要比 DRAM 慢大约 $100\ 000$ 多倍。因此，**DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多**，这是因为 **DRAM 缓存不命中要由磁盘来服务**，而 SRAM 缓存不命中通常是由基于 DRAM 的主存来服务的。而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 $10\ 000$ 倍。归根到底，DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的

因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 $4\text{KB} \sim 2 \text{MB}$。**由于大的不命中处罚，DRAM 缓存是全相联的，即任何虚拟页都可以放置在任何的物理页中**。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。最后，因为对磁盘的访问时间很长，**DRAM 缓存总是使用写回**，而不是直写

> [!tip] 
> 
> 写回：DRAM 缓存的页被替换时，才写入磁盘
> 

### 页表

同任何缓存一样，虚拟内存系统必须有某种方法来 **判定一个虚拟页是否缓存在 DRAM 中的某个地方**。如果 **命中**（虚拟页缓存在 DRAM 中），系统还必须 **确定这个虚拟页存放在哪个物理页中**。如果 **不命中**（虚拟也没有缓存在 DRAM 中），系统必须 **判断这个虚拟页存放在磁盘的哪个位置**，在物理内存中选择一个 **牺牲页**，并 **将虚拟页从磁盘复制到 DRAM中**，替换这个牺牲页

这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做 **页表** 的数据结构，

> [!tip] 
> 
> 页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页
> 

下图展示了一个 **页表的基本组织结构**。页表就是一个 **页表条目**（Page Table Entry，**PTE**)的 **数组**。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。为了我们的目的，我们将假设每个 PTE 是由一个 **有效位** 和一个 **$n$ 位地址字段** 组成的

![Pasted image 20241028211143|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989346-b9191b7038ec4c6eb0718af08fb1e10a.png)

> [!tip] 有效位：表面该虚拟页是否被缓存在 DRAM 中
> + 如果 **设置了有效位**，那么地址字段就表示 DRAM 中相应的物理页的起始位置，这个 **物理页中缓存了该虚拟页**
> + 如果 **没有设置有效位**，那么一个 **空地址表示这个虚拟页还未被分配**。否则，这个 **地址就指向该虚拟页在磁盘上的起始位置**
> 

### 页命中

考虑一下当 CPU 想要读包含在 VP2 中的虚拟内存的一个字时会发生什么

![Pasted image 20241028211334|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989347-ba8a67c8ac874230bb2ccc0e82868153.png)

VP2 被缓存在 DRAM 中。地址翻译硬件将 **虚拟地址作为一个索引来定位 PTE2**, 并从内存中读取它。因为设置了有效位，那么地址翻译硬件就知道 VP2 是缓存在内存中的了。所以它使用 PTE 中的物理内存地址（该地址指向 PP1 中缓存页的起始位置），构造出这个字的物理地址

### 缺页

在虚拟内存的习惯说法中，DRAM 缓存不命中称为 **缺页**。下图展示了 在 **缺页之前** 我们的示例页表的状态

![Pasted image 20241028211450|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989347-b70d3d5f005349ca947af36b903b16d9.png)

CPU 引用了 VP3 中的一个字，VP3 并未缓存在 DRAM 中。地址翻译硬件从内存中读取 PTE3，从有效位推断出 VP3 未被缓存，并且触发一个 **缺页异常**

> [!tip] 
> 
> **缺页异常** 调用内核中的 **缺页异常处理程序**，该程序会 **选择一个牺牲页**
> 

在此例中我们选中的 **牺牲页** 存放在 PP3 中的 VP4。如果 VP4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP4 的页表条目，反映出 VP4 不再缓存在主存中这一事实

接下来，内核从磁盘复制 VP3 到内存中的 PP3，更新 PTE3，随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在，VP3 已经缓存在主存中了，那么页命中也能由地址翻译硬件正常处理了。下图图展示了在 **缺页之后** 我们的示例页表的状态

![Pasted image 20241028211717|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989349-81a7625c863145c893e69655a55e89d0.png)

虚拟内存是在 20 世纪 60 年代早期发明的，远在 **CPU-内存** 之间差距的加大引发产生 SRAM 缓存之前。因此，虚拟内存系统使用了和 SRAM 缓存不同的术语，即使它们的许多概念是相似的。在虚拟内存的习惯说法中，块被称为 **页**。在磁盘和内存之间传送页的活动叫做 **交换** 或者 **页面调度**

> [!tip] 
> 
> 页从磁盘换入（或者页面调入）DRAM 和从 DRAM 换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为 **按需页面调度**（demand paging)
> 
> 也可以采用其他的方法，例如尝试着 **预测不命中**，在页面实际被引用之前就换入页面。然而，所有现代系统都使用的是按需页面调度的方式
> 

### 分配页面

下图展示了当操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 `malloc` 的结果。在这个示例中，VP5 的分配过程是在磁盘上创建空间并更新 PTE5，使它指向磁盘上这个新创建的页面

![Pasted image 20241028211918|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989349-9dd968dcf19c44119939af66e268fd84.png)


### 局部性拯救了我们

当我们中的许多人都了解了虚拟内存的概念之后，我们的第一印象通常是它的效率应该是非常低。因为不命中处罚很大，我们担心页面调度会破坏程序性能。实际上，虚拟内存工作得相当好，这主要归功于我们的老朋友 **局部性**

尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的 **活动页面** 集合上工作，这个集合叫做 **工作集** 或者 **常驻集合**

> [!tip] 
> 
> 在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量
> 
> 只要我们的程序有好的 **时间局部性**，虚拟内存系统就能工作得相当好。但是，当然不是所有的程序都能展现良好的时间局部性
> 
> 如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做 **抖动**，这时页面将不断地换进换出。虽然虚拟内存通常是有效的，但是如果一个程序性能慢得像爬一样，那么聪明的程序员会考虑是不是发生了抖动
> 

## 虚拟内存作为内存管理工具

到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，**操作系统为 _每个进程提供了一个独立的页表_，因而也就是一个 _独立的虚拟地址空间_**

![Pasted image 20241028212315|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989350-242cdd0ed2754b51b7f6a60d69bafa8d.png)

在这个示例中，进程 $i$ 的页表将 VP1 映射到 PP2，VP2 映射到 PP7。相似地，进程 $j$ 的页表将 VP1 映射到PP7，VP2 映射到 PP10。注意，**多个虚拟页面可以映射到同一个共享物理页面上**。

按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别地，**VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配**

> [!tip] 
> 
> **简化链接**：独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处
> 
> **简化加载**：虚拟内存还使得容易向内存中加载可执行文件和共享对象文件
> 
> **简化共享**。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，**每个进程都有自己私有的代码、数据、堆以及栈区域**，是不和其他进程共享的。在这种情况中，**操作系统创建页表，将相应的虚拟页映射到不连续的物理页面**
> 
> **简化内存分配**。虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如调用 `malloc` 的结果），操作系统分配一个适当数字（例如 $k$）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的 $k$ 个任意的物理页面。由于页表工作的方式，操作系统没有必要分配 $k$ 个连续的物理内存页面。页面可以随机地分散在物理内存中
> 

## 虚拟内存作为内存保护的工具

任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问

> [!tip] 
> 
> **不应该允许修改它的只读代码段**。**不应该允许** 用户进程 **读或者写其他进程的私有内存**，并且**不允许** 用户进程 **修改任何与其他进程共享的虚拟页面**，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）
> 

就像我们所看到的，**提供独立的地址空间使得区分不同进程的私有内存变得容易**。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次 **CPU 生成一个地址** 时，地址翻译硬件都会 **读一个 PTE**，所以通过 **在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单**。下图展示了大致的思想。在这个示例中，每个 PTE 中已经添加了三个许可位。

![Pasted image 20241028212918|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989351-1d07bd8121ec46389149bfbe1d6aab59.png)

> [!tip] 
> 
> **SUP 位** 表示进程是否必须运行在内核 (超级用户) 模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 $0$ 的页面
> 
> **READ位** 和 **WRITE位** 控制对页面的读和写访问
> 

如果进程 $i$ 运行在用户模式下，那么它有读 VP0 和读写 VP1 的权限。然而，不允许它访问 VP2。如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell—般将这种异常报告为 **“段错误”**

## 地址翻译


这一节讲述的是地址翻译的基础知识。我们的目标是让你了解硬件在支持虚拟内存中的角色，并给出足够多的细节使得你可以亲手演示一些具体的示例。不过，要记住我们省略了大量的细节，尤其是和时序相关的细节，虽然这些细节对硬件设计者来说是非常重要的，但是超出了我们讨论的范围。下图概括了我们在这节里将要使用的所有符号，供读者参考

![Pasted image 20241028213212|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989351-7efa62249599422c8891b0fb3780fd61.png)

形式上来说，地址翻译是一个 $N$ 元素的虚拟地址空间(VAS)中的元素和一个 $M$ 元素的物理地址空间(PAS)中元素之间的映射

$$\text{MAP}: \text{VAS} \rightarrow \text{PAS} \cup \emptyset$$
$$\text{MAP}(A) = \begin{cases} A^{\prime} & \text{虚拟地址 A 处的数据在 PSA 的物理地址} A^{\prime} \text{处} \\ \emptyset & \text{虚拟地址 A 处的数据不在物理内存中}\end{cases}$$

下图展示了 MMU 如何利用页表来实现这种映射

![Pasted image 20241028213544|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989353-14b5296af1484457b70f08968ba4e217.png)

CPU 中的一个控制寄存器，**页表基址寄存器**(PTBR) 指向当前页表。$n$ 位的虚拟地址包含两个部分：一个 $p$ 位的 **虚拟页面偏移**（Virtual Page Offset，**VPO**)和 一个 $(n-p)$ 位的 **虚拟页号**（Virtual Page Number，**VPN**)

> [!tip] 
> 
> MMU 利用 VPN 来选择适当的 PTE。例如，VPN $0$ 选择 PTE $0$，VPN $1$ 选择 PTE $1$，以此类推
> 

将页表条目中 **物理页号**(Physical Page Number，PPN)和 **虚拟地址中的 VPO** 串联起来，就得到相应的物理地址

> [!attention] 
> 
> 注意，因为物理和虚拟页面都是 $P$ 字节的，所以 **物理页面偏移**（Physical Page Offset,**PPO**)和 **VPO** 是相同的
> 

下图展示了当页面命中时，CPU 硬件执行的步骤

![Pasted image 20241028213835|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989354-f90ab25ef8244254865ff60204ebd9ce.png)

- 第 1 步：处理器生成一个虚拟地址，并把它传送给 MMU
- 第 2 步：MMU 生成 PTE 地址，并从高速缓存/主存请求得到它
- 第 3 步：高速缓存/主存向 MMU 返回 PTE
- 第 4 步：MMU 构造物理地址，并把它传送给高速缓存/主存
- 第 5 步：高速缓存/主存返回所请求的数据字给处理器

**页面命中完全是由硬件来处理的**，与之不同的是，**处理缺页要求硬件和操作系统内核协作完成**，如下图所示

![Pasted image 20241028213933|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989355-cbfdf3e8ce22449ebec228ddbde02d43.png)

- 第 1 步：处理器生成一个虚拟地址，并把它传送给 MMU
- 第 2 步：MMU 生成 PTE 地址，并从高速缓存/主存请求得到它
- 第 3 步：高速缓存/主存向 MMU 返回 PTE
- 第 4 步：PTE 中的有效位是零，所以 MMU 触发了一次异常，传递 CPU 中的控制到操作系统内核中的缺页异常处理程序
- 第 5 步：缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘
- 第 6 步：缺页处理程序调入新的页面，并更新内存中的 PTE
- 第 7 步：缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU 将引起缺页的虚拟地址重新发送给 MMU 因为虚拟页面现在缓存在物理内存中，所以就会命中，在 MMU 执行了上图的步骤之后，主存就会将所请求字返回给处理器

### 结合高速缓存的虚拟内存

在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题

> [!tip] 
> 
> **大多数系统是选择物理寻址的方式访问 SRAM 高速缓存**

使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，**高速缓存无需处理保护问题，因为 _访问权限的检査是地址翻译过程的一部分_**

下图展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要的思路是 **地址翻译发生在高速缓存查找之前**。注意，**页表条目可以缓存**，就像其他的数据字一样

![Pasted image 20241028214404|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989356-757285aa7a24411183b9818063790a15.png)

### 利用 TLB 加速地址翻译

正如我们看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期。**如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 $1$ 个或 $2$ 个周期**

然而，许多系统都试图消除即使是这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为 **翻译后备缓冲器**（Translation Lookaside Buffer，TLB)

> [!tip] 
> 
> **TLB** 是一个小的 _虚拟寻址_ 的 **缓存**，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度
> 

如下图所示，用于 **组选择** 和 **行匹配** 的索引和 **标记字段** 是从虚拟地址中的虚拟页号中提取出来的

![Pasted image 20241028214609|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989357-71e8986364d641528f8221679c8fd453.png)

> [!tip] 
> 
> 如果 TLB 有 $T=2^t$ 个组，那么 **TLB 索引(TLBI)** 是由 VPN 的 $t$ 个最低位组成的，而 **TLB 标记(TLBT)** 是由 VPN 中剩余的位组成的
> 

下图展示了当 **TLB 命中** 时(通常情况)所包括的步骤。这里的关键点是，所有的地址翻译步骤都是在芯片上的 MMU 中执行的，因此非常快

![Pasted image 20241028214717|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989357-6cd3eff5c4634dc7ac7803405cfd12f5.png)

- 第 1 步：CPU 产生一个虚拟地址
- 第 2 步和第 3 步：MMU 从 TLB 中取出相应的 PTE
- 第 4 步：MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存
- 第5步：高速缓存/主存将所请求的数据字返回给 CPU

当 **TLB 不命中** 时，MMU 必须从 L1缓存中取出相应的 PTE，如下图所示。新取出的 PTE 存放在 TLB 中，可能会覆盖一个已经存在的条目

![Pasted image 20241028214850|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989358-6d0670d36c504aa5b5532ddf302c6e89.png)

### 多级页表

到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译。但是如果我们有一个 $32$ 位的地址空间、$4KB$ 的页面和一个 $4$ 字节的 PTE，那么即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个 $4MB$ 的页表驻留在内存中。对于地址空间为 $64$ 位的系统来说，问题将变得更复杂

用来压缩页表的常用方法是使用 **层次结构的页表**。用一个具体的示例是最容易理解这个思想的。假设 $32$ 位虚拟地址空间被分为 $4\ KB$ 的页，而每个页表条目都是 $4$ 字节。还假设在这一时刻，虚拟地址空间有如下形式：内存的前 $2\ K$ 个页面分配给了代码和数据，接下来的$6\ K$ 个页面还未分配，再接下来的 $1023$ 个页面也未分配，接下来的 $1$ 个页面分配给了用户栈。下图展示了我们如何为这个虚拟地址空间构造一个两级的页表层次结构

![Pasted image 20241028215027|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989359-26af8b5822a04eacaba48f2d002e91d1.png)

一级页表中的每个 PTE 负责映射虚拟地址空间中一个 $4MB$ 的片，这里每一片都是由 $1024$ 个连续的页面组成的。比如，PTE $0$ 映射第一片，PTE $1$ 映射接下来的一片，以此类推。假设地址空间是 $4\ GB$，$1024$ 个 PTE 已经足够覆盖整个空间了

如果片 $i$ 中的每个页面都未被分配，那么一级 $\text{PTE}_i$ 就为空。例如，上图中，片 $2 \sim 7$ 是未被分配的。然而，如果在片 $i$ 中至少有一个页是分配了的，那么一级 $\text{PTE}_i$ 就指向一个二级页表的基址。例如上在图中，片 $0, 1, 8$ 的所有或者部分已被分配，所以它们的一级 PTE 就指向二级页表

二级页表中的每个 PTE 都负责映射一个 $4KB$ 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用 $4$ 字节的 PTE，每个一级和二级页表都是 $4KB$ 字节，这刚好和一个页面的大小是一样的

> [!tip] 这种方法从两个方面减少了内存要求
> 
> 第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB的虚拟地址空间的大部分都会是未分配的
> 
> 第二，只有一级页表才需要总是在主存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中
> 

下图描述了使用 $k$ 级页表层次结构的地址翻译。虚拟地址被划分成为 $k$ 个 VPN 和 $1$ 个VPO。每个 $\text{VPN}_i$ 都是一个到第 $i$ 级页表的索引，其中 $1 \le i \le k$。第 $j$ 级页表中的每个PTE，$1 \le j \le k - 1$，都指向第 $j+1$ 级的某个页表的基址。第 $k$ 级页表中的每个 PTE 包含某个物理页面的 PPN，或者一个磁盘块的地址。为了构造物理地址，在能够确定 PPN 之前，MMU 必须访问 $k$ 个 PTE。对于只有一级的页表结构，PPO 和 VPO 是相同的

![Pasted image 20241028215753|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989361-a57e177bd0884e48b2fc5a680df078a4.png)

访问 $k$ 个 PTE，第一眼看上去昂贵而不切实际。然而，这里 TLB 能够起作用，正是通过将不同层次上页表的 PTE 缓存起来。实际上，带多级页表的地址翻译并不比单级页表慢很多

### 综合：端到端的地址翻译示例

这个示例运行在有一个 TLB 和 L1 d-cache 的小系统上。为了保证可管理性，我们做出如下假设

> [!tip] 假设
> 
> 内存是按字节寻址的
> 
> 内存访问是针对 $1$ 字节的字的(不是4字节的字）
> 
> 虚拟地址是 $14$ 位长的($n=14$)
> 
> 物理地址是 $12$ 位长的($m=12$)
> 
> 页面大小是 $64$ 字节($P=64$)
> 
> TLB 是四路组相联的，总共有 $16$ 个条目
> 
> L1 d-cache 是物理寻址、直接映射的，行大小为 $4$ 字节，而总共有 $16$ 个组
> 

下图展示了虚拟地址和物理地址的格式。因为每个页面是字节，所以虚拟地址和物理地址的低 $6$ 位分别作为 VPO 和 PPO。虚拟地址的高 $8$ 位作为 VPN，物理地址的高 $6$ 位作为 PPN

![Pasted image 20241028215953|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989362-744cddf61e924f4daf05522ec08a3cc9.png)

下面介绍了小内存系统的一个快照，包括 **TLB**(图a)、**页表的一部分**(图b)和 **L1高速缓存**(图c)。在 TLB 和高速缓存的图上面，我们还展示了访问这些设备时硬件是如何划分虚拟地址和物理地址的位的

> [!tip] **TLB**
> 
> TLB 是利用 VPN 的位进行 **虚拟寻址** 的。因为 TLB 有 $4$ 个组，所以 VPN 的 **低 2 位** 就作为 **组索引**(TLBI)。VPN中剩下的 **高6位** 作为 **标记**(TLBT),用来区别可能映射到同一个TLB组的不同的 VPN
> 
> ![Pasted image 20241028220142|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989363-2325216ac9d3463fa3a9d600412b85ad.png)
> 

> [!tip] **页表**
> 
> 这个页表是一个 **单级设计**，一共有 $2^8=256$  个页表条目(PTE)。然而，我们只对这些条目中的开头 $16$ 个感兴趣
> 
> 为了方便，我们用索引它的 VPN 来标识每个 PTE；但是要记住这些 VPN 并不是页表的一部分，也不储存在内存中
> 
> 另外，注意每个无效 PTE 的 PPN 都用一个破折号来表示，以加强一个概念：无论刚好这里存储的是什么位值，都是没有任何意义的
> 
> ![Pasted image 20241028220301|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989364-6b30e6c7b69945b1bd4e3b6322c5d22f.png)
> 

> [!tip] **高速缓存**
> 
> 直接映射的缓存是通过 **物理地址** 中的字段来寻址的。因为每个块都是 $4$ 字节，所以物理地址的低 $2$ 位作为块偏移(CO)。因为有 $16$ 组，所以接下来的 $4$ 位就用来表示组索引(CI)。剩下的 $6$ 位作为标记(CT)
> 
> ![Pasted image 20241028220358|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989365-93b271fa1cab4624b8c4e625f772180a.png)
> 

给定了这种初始化设定，让我们来看看当 CPU 执行一条读地址 `0x03d4` 处字节的加载指令时会发生什么。（回想一下我们假定 CPU 读取 $1$ 字节的字，而不是 $4$ 字节的字。）为了开始这种手工的模拟，我们发现写下虚拟地址的各个位，标识出我们会需要的各种字段，并确定它们的十六进制值，是非常有帮助的。当硬件解码地址时，它也执行相似的任务

![Pasted image 20241028220435|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989366-f19d58d28caa490597ceddc69f39fc4c.png)

开始时，MMU 从虚拟地址中抽取出 VPN(`0x0F`)，并且检查 TLB，看它是否因为前面的某个内存引用缓存了PTE `0x0F`的一个副本
+ TLB 从 VPN 中抽取出 TLBI (`0x03`) 和 TLBT(`0x03`)，组 `0x03` 的第二个条目中有效匹配，所以命中，然后将缓存的 PPN(`0x0d`)返回给 MMU

如果 TLB 不命中，那么 MMU 就需要从主存中取出相应的 PTE。然而，在这种情况中，我们很幸运，TLB 会命中。现在，MMU 有了形成物理地址所需要的所有东西。它通过将来自 PTE 的 PPN (`0x0D`) 和来自虚拟地址的 VPO(`0x14`) 连接起来，这就形成了物理地址(`0x354`)

![Pasted image 20241028220820|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989367-8ecf0d42517d438ea98771bd746eb021.png)

接下来，MMU 发送物理地址给缓存，缓存从物理地址中抽取出 **缓存偏移CO**(`0x0`)，**缓存组索引 CI**(`0x5`)以及 **缓存标记 CT**(`0x0D`)。因为组 `0x5` 中的标记与 CT 相匹配，所以缓存检测到一个命中，读出在偏移量 CO 处的数据字节（`0x36`)，并将它返回给 MMU，随后 MMU 将它传递回 CPU

下图描述了上述示例的整个过程

![Pasted image 20241028221027|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989367-b3bf4e16d5944005a7bcb7782c3b83c8.png)

想一想，如何从磁盘加载可执行程序到内存。一种选择是，在程序执行时将整个程序加载到物理内存。然而，这种方法的一个问题是，最初可能不需要整个程序都处于内存。假设程序开始时带有一组用户可选的选项。加载整个程序会导致所有选项的执行代码都加载到内存中，而不管这些选项是否最终使用。另一种策略是，仅在需要时才加载页面。这种技术被称为 **请求调页**(demand paging)，常常用于虚拟内存系统。对于请求调页的虚拟内存，页面只有在程序执行期间被请求时才被加载。因此，从未访问的那些页从不加载到物理内存中

## Linux 虚拟内存系统

这里我们大致了解 Linux 的虚拟内存系统是如何组织虚拟内存，以及如何处理缺页的。Linux 为每个进程维护了一个单独的虚拟地址空间，如下图所示

![Pasted image 20241028225113|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989370-56aa9a20609c4c0daf30b2e5f9164adf.png)

> [!tip] **内核虚拟内存** 
> 
> 内核虚拟内存存储了内核使用的代码和数据结构。它的某些区域被映射到所有进程的共享的物理页面
> + 每个进程共享内核的代码和全局数据结构
> 
> + Linux 将一组连续的虚拟页面映射到相应的一组连续的物理页面。为内核提供了一种便利的方法来访问物理内存中任何特定的位置
> 	+  例如，当它需要访问页表，或者设备上执行内存映射的 IO 操作，而这些设备被映射到特定的物理内存位置
> 
> + 内核虚拟内存的其他区域包含每个进程不相同的数据
> 	+ 页表、内核进程的上下文中执行代码时使用的栈，记录虚拟地址空间当前组织的各种数据结构

### 虚拟内存区域

Linux 将虚拟内存组织成一些 **区域**，也叫做 **段**，的集合。一个 **区域** 就是已经存在的（已分配的）虚拟内存的连续片段，这些页是以某种方式相关联的。

每个存在的虚拟页面都保存在某个区域中，而不属于某个区域的虚拟页是不存在的

>[!tip] 
>
>区域概念允许虚拟空间由间隙。内核不用记录那些不存在的虚拟页，这样的页页不占用内存、磁盘或者内核本身中的任何资源
>

下图强调了记录一个进程中虚拟内存区域的内核数据结构

![Pasted image 20241028225517|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989373-14a65b3714224493b229e445092b66e2.png)

内核为系统中的每个进程维护了一个单独的 **任务结构** `task_struct`。任务结构中的元素包含或者指向内核 **运行该进程所需要的所有信息**

> [!tip]
> 
> 例如：PID，指向用户栈的指针，可执行目标文件的名字，程序计数器
> 

任务结构中的一个条目 `mm_struct` 描述了虚拟内存的当前状态

+ 字段 `pgd`：指向 **第一级页表的基地址**
+ 字段 `mmap`：指向第一个 **虚拟内存区域结构** `vm_area_struct`

区域结构包含下面的字段
- `vm_start`：区域的起始地址
- `vm_end`: 区域的结束地址
- `vm_port`：描述这个区域包含所有页的读写许可权限
- `vm_flags`：描述这个区域的页面是与其他进程共享的，还是进程私有的
- `vm_next`：指向链表中的下一个区域结构

### 缺页异常处理

假设 MMU 在试图翻译某个地址 `A` 时，触发了一个缺页。这个异常导致控制转向内核的缺页处理程序，执行下面的步骤：

> [!tip] 
> 
> **检查虚拟地址是否合法**（`A`是否在区域结构定义的区域内）：搜索区域结构的链表，把 `A` 和每个区域结构中的 `vm_start` 和 `vm_end` 做比较。如果虚拟地址不合法，则触发段错误，结束程序运行
> 
> **检查内存访问是否合法**（进程是否有读、写或执行这个区域内页面的权限）：比如，缺页是否是试图对代码段里的只读页面进行写操作造成的
> 
> 到此，合法性检查完毕。**开始处理缺页**：选择牺牲页，如果牺牲页被修改过，那么它将交换出去，换入新的页面并更新页表
> 
> 缺页处理程序返回，CPU 重新启动引起缺页的指令，这条指令再次发送 `A` 到 `MMU`
> 

下图显示了缺页处理的过程

![Pasted image 20241028230019|600](http://cdn.jsdelivr.net/gh/duyupeng36/images@master/obsidian/1755706989382-bdb68dfc41774591be53ad640596da36.png)

## 内存映射

Linux 通过将一个 **虚拟内存区域** 与一个 **磁盘上的对象(object) 关联起来**，以初始化这个虚拟内存区域的内容，这个过程称为 **内存映射**(memory mapping)。虚拟内存区域 **可以映射到两种类型的对象中的一种**
- **Linux文件系统中的普通文件**：一个区域可以映射到一个 **普通磁盘文件** 的连续部分，例如一个可执行目标文件。**文件区**(section)被分成页大小的片，每一片包含一个虚拟页面的初始内容。因为按需进行页面调度(请求调页)，所以这些虚拟页面没有实际交换进入物理内存，直到CPU第一次引用到页面(即发射一个虚拟地址，落在地址空间这个页面的范围之内)。如果区域比文件区要大，那么就用零来填充这个区域的余下部分
- **匿名文件**：一个区域也可以映射到一个**匿名文件**，匿名文件是由内核创建的，包含的 **全是二进制零**。CPU第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间并没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做 **请求二进制零的页**

无论在哪种情况中旦一个 **虚拟页面被初始化** 了，它就在一个由内核维护的专门的 **交换文件**（swap file)之间换来换去。交换文件也叫做 **交换空间**(swap space)或者 **交换区域**(swap area)。需要意识到的很重要的一点是，在任何时刻，**交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数**

关于内存映射的详细内容，可以参考 [[Linux 系统编程：内存映射]]

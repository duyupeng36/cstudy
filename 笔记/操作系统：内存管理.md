# 内存管理

> [!tip] **内存是现代计算机运行的核心**
> 
> 内存被抽象为一个很大的字节数组，然而内存的实际结构并不是线性的，参考 [[计算机组成：存储器层次结构#存储技术#随机访问存储器#DRAM]] 
> 
> 因为将内存抽象为了一个很大的字节数组，因此每个字节都有一个索引，这个索引被称为 **地址**
> 
> CPU 根据程序计数器(Program Counter, PC) 的值从内存中读取指令。这些指令可能会引用其他特定的内存地址
> 

## 内存管理基础

### 硬件

CPU 可以 **直接访问** 的通用存储只有 **主存** 和 CPU 内置的 **寄存器**。机器指令可以用内存地址作为参数，而不能用磁盘地址作为参数

> [!hint] 
> 
> 执行 **指令** 以及指令使用的 **数据**，应处在这些 **可直接访问的存储设备上**。如果数据不在内存中，那么在 CPU 使用它们之前应先把数据移到内存
> 

CPU 内置寄存器通常可以在一个 CPU 时钟周期内完成访问。对于寄存器的内容，大多数CPU 可以在一个时钟周期内解释并执行一条或多条指令

对于内存，它可通过 **内存总线** 的事务来访问。也就意味着不能在一个 CPU 时钟周期内完成。**完成内存的访问可能需要多个 CPU 时钟周期**

> [!tip] 
> 
> 内存访问需要通过 **总线**，由于 CPU 没有数据以便完成正在执行的指令，CPU 通常需要 **暂停**，等待数据到达 CPU 
> 

由于内存访问的频繁，这种情况是无法容忍的。补救措施是在 CPU 与内存之间，通常是在 CPU 芯片上，增加更快的内存；这称为 **高速缓存**( cache)。为管理 CPU 内置的缓存，硬件自动加快内存访问，无需任何操作系统的控制

我们不仅关心访问物理内存的相对速度，而且还要确保操作的正确。为了系统操作的正确，**我们应保护操作系统，而不被用户进程访问**。在多用户系统上，我们还应 **保护用户进程不会互相影响**

> [!tip] 
> 
> 在 [[操作系统：进程调度]] 中，我们直到内存存储了许多进程的代码和数据，其中包括 **用户进程** 和 **内核**。用户进程不应该访问内核，也不应该访问其他用户进程中的数据
> 

上述保护机制应该通过 **硬件来实现**，因为 **操作系统通常不干预 CPU 对内存的访问**，从而避免性能损失。硬件实现具有多种不同方式。这里，我们简述一种可能的实现

> [!tip] 内存保护的硬件实现
> 
> 首先，我们需要 **确保每个进程都有一个单独的内存空间**。单独的进程内存空间可以保护进程而不互相影响，这对于将多个进程加到内存以便并发执行来说至关重要。为了分开内存空间，我们需要 **能够确定一个进程 _可以访问的合法地址的范围_**；并且确保该进程只能访问这些合法地址
> 
> 通过两个寄存器：**基地址** 和 **界限地址(偏移)**，如下图
> 
> ![[Pasted image 20241028184044.png]]
> 
> + **基地址寄存器**：最小的合法的物理内存地址
> + **界限地址寄存器**：指定了 **范围的大小**
> 
> 内存空间保护的实现是通过 CPU 硬件对在用户模式下产生的地址与寄存器的地址进行比较来完成的。当 **在用户模式下** 执行的 **程序试图访问操作系统内存** 或 **其他用户内存** 时，会陷入操作系统，而操作系统则将它作为 **致命错误来处理**。这种方案防止用户程序无意或故意修改操作系统或其他用户的代码或数据结构
> 
> ![[Pasted image 20241028184248.png]]
> 
> **只有操作系统可以通过特殊的特权指令，才能加载基地址寄存器和界限地址寄存器**。由于特权指令只能在内核模式下执行，而只有操作系统才能在内核模式下执行，所以只有操作系统可以加载基地址寄存器和界限地址寄存器。这种方案允许操作系统修改这两个寄存器的值，而不允许用户程序修改它们
>  

 在 **内核模式下** 执行的操作系统可以 **无限制地访问操作系统及用户的内存**。这项规定允许操作系统：加载用户程序到用户内存，转储出现错误的程序，访问和修改系统调用的参数，执行用户内存的I/O，以及提供许多其他服务等

### 地址绑定

在大多数情况下，用户程序在执行前，需要经过好几个步骤，其中有的是可选的

![[Pasted image 20241028184453.png]]

> [!tip] 
> 在这些步骤中，**地址可能会有不同表示形式**
> + **源程序** 中的 **地址** 通常是用 **符号表示**(如变量 `count`)
> + **编译器** 通常将这些 **符号地址 _绑定_ 到可重定位的地址** (如 "从本模块开始的第 $14$ 字节")
> + **链接程序** 或 **加载程序** 再将这些 **可重定位的地址 _绑定_ 到绝对地址**(如 `74014`)
>   
> 每次绑定都是从一个地址空间到另一个地址空间的映射

通常，指令和数据绑定到存储器地址可在沿途的任何一步中进行
+ **编译时**：如果在编译时就 **_已知道_ 进程将在内存中的驻留地址**，那么就可以生成绝对代码
+ **加载时**：如果在编译时**并 _不知道_ 进程将驻留在何处**，那么编译器就应生成可重定位代码。对这种情况，**_最后绑定_ 会延迟到加载时才进行**。如果开始地址发生变化，那么只需重新加载用户代码以合并更改的值
+ **执行时**：如果进程在执行时 **可以从一个内存段移到另一个内存段**，那么 **绑定应延迟到执行时才进行**。采用这种方案需要特定硬件才行。大多数的通用计算机操作系统采用这种方法

### 逻辑地址空间和物理地址空间

CPU生成的地址通常称为 **逻辑地址**；而 内存单元看到的地址通常称为 **物理地址**，即加载到 **内存地址寄存器** 的地址

编译时和加载时的地址绑定方法生成相同的逻辑地址和物理地址。然而，执行时的地址绑定方案生成不同的逻辑地址和物理地址。在这种情况下，我们通常称逻辑地址为 **虚拟地址**。我们对逻辑地址和虚拟地址不加区别。由程序所生成的所有逻辑地址的集合称为 **逻辑地址空间**，这些逻辑地址对应的所有物理地址的集合称为 **物理地址空间**。因此，对于执行时地址绑定方案，逻辑地址空间与物理地址空间是不同的

从虚拟地址到物理地址的运行时映射是由 **内存管理单元**(Memory-Management Unit，MMU) 的硬件设备来完成。基地址寄存器这里称为 **重定位寄存器**。用户进程所生成的地址在送交内存之前，都将加上重定位寄存器的值。例如，如果基地址为 $14000$，那么用户对位置 $0$ 的访问将动态地重定位为位置 $14000$；对地址 $346$ 的访问将映射为位置 $14346$

![[Pasted image 20241028185153.png]]

> [!tip] 
> 
> **用户程序不会看到真实的物理地址**。程序可以创建一个指向位置 $346$ 的指针，将它保存在内存中，使用它，将它与其他地址进行比较等，所有这些都是通过 $346$ 这样一个数字来进行。只有当它作为内存地址时(例如，在间接加载和保存时)，它才会相对于基地址寄存器进行重定位
> 
> + **用户程序处理逻辑地址**；内存映射硬件将逻辑地址转变为物理地址
> 

### 动态加载

在迄今为止的讨论中，一个进程的整个程序和所有数据都应在物理内存中，以便执行。因此，进程的大小受限于内存的大小。为了获得更好的内存空间利用率，可以使用 **动态加载**。采用动态加载时，**一个程序只有在调用时才会加载**。**所有程序都以可重定位加载格式保存在磁盘上**

> [!tip] 
> 
> 动态加载：让程序以 **可重定位格式** 保存在磁盘上，内存中只加载程序运行必要的数据，当进程需要时，才将需要的数据加载到内存
> 

动态加载的优点是：**只有一个程序被需要时，它才会被加载**。当大多数代码需要用来处理异常情况时，如错误处理，这种方法特别有用。在这种情况下，虽然整个程序可能很大，但是所用的(和加载的)部分可能很小。

**动态加载不需要操作系统提供特别支持**。用户的责任是，设计他们的程序利用这种方法的优点。然而，操作系统可以通过实现动态加载的程序库来帮助程序员

### 动态链接和共享库

**动态链接库** 为系统库，**可链接到用户程序，以便运行**。有的操作系统只支持 **静态链接**：它的系统库与其他目标模块一样，通过加载程序，被合并到二进制可执行程序中

动态链接类似于动态加载。这里，不是加载而是链接，加载会延迟到运行时。这种功能通常用于系统库。没有这种功能，系统内的所有程序都需要一份语言库的副本(或至少那些被程序所引用的子程序)。这种要求浪费了磁盘空间和内存空间

如果有动态链接，在二进制可执行程序内，每个库程序的引用都有一个**存根**。存根是一小段代码，用来指出 **如何定位适当的内存驻留库程序**，或者在 **程序不在内存内时应如何加载库**

> [!tip] 
> 
> 当执行存根时，它首先检查所需程序是否已在内存中。如果不在，就将程序加到内存
> 
> 不管如何，存根会用程序地址来替换自己，并开始执行程序。因此，下次再执行该程序代码时，就可以直接进行，而不会因动态链接产生任何开销。采用这种方案，使用语言库的所有进程只需要一个库代码副本就可以了
> 

**动态链接通常需要操作系统的帮助**。如果内存中的进程是彼此保护的，那么只有操作系统才可以检查所需程序是否在某个进程的内存空间内，或是允许多个进程访问同样的内存地址

## 交换

**进程 _必须_ 在内存中以便执行**。不过，进程可以暂时从内存 **交换** 到备份存储，当再次执行时再调回到内存中。交换有可能让所有进程的总的物理地址空间超过真实系统的物理地址空间，从而增加了系统的多道程序程度

![[Pasted image 20241028190344.png]]

## 内存管理：连续分配

内存应该容纳 **内核** 和 **用户进程**。因此，内存应该尽可能的有效分配。**连续分配** 是最早的内存分配方法

> [!tip] 连续分配
> 
> 每个进程位于一个连续的内存区域，并且 **紧挨着** 下一个进程的内存区域
> 

连续分配方法间内存划分 **固定大小的分区**，每个分区可以只包含一个进程。这样多道程序数受限于分区数

> [!hint] 
> 
> 只要有一个空闲分区，就可以从输入队列中选择一个进程，调入空闲分区
> 
> 当进程终止时，它的分区可以被其他进程使用
> 

> [!attention] 固定大小分区的缺陷
> 
> + 某些进程可能不会使用到分区的所有内存，从而造成 **空间浪费**
> + 某些进程可能需要更大的分区，从而造成 **程序无法运行**
> 

为了解决固定大小分区的缺陷，可以采用 **可变分区**。操作系统提供一张表，用于记录哪些内存可以使用，哪些内存不能使用。

> [!attention] 可变分区的缺陷
> 
> + 随着进程的载入和终止，可能造成剩余空间足够容纳新的进程，然而内存中的任何空闲区域都不足够容纳这个新进程的尴尬情况。这就是 **内存碎片** 问题
> 

## 内存管理：分段

在连续分配中，将物理内存和用户内存视图看做一样的字节线性数组。然而，用户内存视图好物理内存是不一样的。

程序员眼中的程序如下图，**将内存看作一组不同长度的段**，这些段之间并没有一定的顺序

![[Pasted image 20241028190709.png]]

当编写程序时，程序员认为它是由主程序加上一组方法、过程或函数所构成的。它还可以包括各种数据结构：对象、数组、堆栈、变量等。每个模块或数据元素通过名称来引用

**分段** 就是支持这种用户视图的内存管理方案。**逻辑地址空间是由一组 _段_ 构成**。每个段都有名称和长度。**地址指定了 _段名称_ 和 _段内偏移_**。因此用户通过两个量来指定地址：**段名称** 和 **段偏移**

> [!tip] 
> 
> 为了实现简单起见，**段是编号的**，是通过 **段号** 而不是段名称来引用。因此，逻辑地址由有序对组成：`<段号，偏移>`
> 

### 分段硬件

虽然用户现在能够通过二维地址来引用程序内的对象，但是实际物理内存仍然是一维的字节序列。因此，我们应定义一个实现方式，以便映射用户定义的二维地址到一维物理地址。这个地址是通过 **段表** 来实现的。段表的每个条目都有 **段基地址** 和 **段界限**

> [!tip] 
> 
> **段基地址** 包含该段在内存中的 **开始物理地址**
> 
> **段界限** 指定该 **段的长度**
> 

如下图是逻辑地址的翻译过程

![[Pasted image 20241028190931.png]]

> [!tip] 
> 
> 每个逻辑地址由两部分组成: **段号 $s$** 和 **段偏移 $d$**
> + **段号 $s$**：段表索引
> + **段偏移 $d$** 应位于 **0 和 段界限之间**。如果不是这样，那么会陷入操作系统中，因为逻辑地址试图访问段的外面
> 
> 如果段偏移 $d$ 合法，那么就与基地址相加而得到所需字节的物理内存地址。因此，**段表实际上是基址寄存器值和界限寄存器值的对的数组**
> 

下图是分段的一个例子

![[Pasted image 20241028191350.png]]

## 内存管理：分页

分段允许进程的物理地址空间是 **非连续** 的。**分页** 是提供这种优势的另一种内存管理方案

> [!tip] 
> 
> **避免了外部 _碎片_ 和 _紧缩_**，而分段不可以
> 
> **避免了将 _不同大小的内存块_ 匹配到交换空间的麻烦问题**
> 

**当位于内存的代码和数据段需要换出时，应在 _备份存储_(通常是磁盘) 上找到空间**。备份存储也有同样的与内存相关的碎片问题，但是访问更慢，因此紧缩是不可能的

由于比早期方法更加优越，各种形式的分页为大多数操作系统采用，包括大型机的和智能手机的操作系统。**实现分页需要操作系统和计算机硬件的协作**

实现分页的基本方法涉及 将 **物理内存** 分为固定大小的块，称为 **帧** 或 **页帧** (frame)；而将 **逻辑内存** 也分为同样大小的块，称为 **页** 或 **页面**(page)

> [!tip] 物理内存和逻辑内存都分为大小固定的块
>  

当需要执行一个进程时，它的页从文件系统或备份存储等源处，加载到内存的可用帧。备份存储划分为固定大小的块，它与单个内存帧或与多个内存帧(簇)的大小一样。这个相当简单的方法功能强且变化多

> [!tip] 
> 
> 备份存储(磁盘)也被划分为固定大小的块，与单个 **内存帧** 或者 **内存帧簇** 的大小相同
> 

**逻辑地址空间现在完全独立于物理地址空间**，因此，一个进程可以有一个 $64$ 位的逻辑地址空间，而系统的物理内存小于 $2^{64}$ 字节

### 分页硬件

分页的硬件逻辑如下图

![[Pasted image 20241028192036.png]]

> [!tip] 
> 
> 由 CPU 生成的每个地址分为两部分: **页码 $p$** 和 **页偏移 $d$**
> + 页码 $p$ 作为 **页表** 索引，其中 **页表** 包含 **每页所在物理内存的基地址**
> + 基地址和页偏移 $d$ 组合就形成了 物理地址，可以发送到物理单元
> 

内存的分页模型如下图所示

![[Pasted image 20241028192353.png]]

**页大小(与帧大小)是由硬件来决定的**。页的大小为 $2$ 的幂；根据计算机体系结构的不同，页大小可从 $512\ bytes$ 到 $1\ GB$ 不等

> [!tip] 
> 
> 将页的大小选为 $2$ 的幂可以方便地将逻辑地址转换为页码和页偏移。如果逻辑地址空间为 $2^m$，且页大小为 $2^n$ 字节，那么 **逻辑地址的高 $m-n$ 位表示页码**，而 **低 $n$ 位表示页偏移**。这样，逻辑地址就如下图所示:
> 
> ![[Pasted image 20241028192523.png]]
> 
> + 页码 $p$ 作为页表索引
> + 页偏移 $d$ 与页表保存的基地址组合形成物理地址
> 

下图是一个具体的例子。这里逻辑地址的 $n = 2, m = 4$。采用大小为 $4$ 字节页而物理内存为 $32$ 字节($8$ 页)

![[Pasted image 20241028192642.png]]

- 逻辑地址 $0=0000_2$ 的页码为 $p=00_2 = 0$ 页偏移为 $d=00_2 = 0$。根据页表，可以查到页码 $0$ 对应帧 $5$，因此，逻辑地址 $0$ 映射到物理地址 $20 [= (5 \times 4) + 0]$
- 逻辑地址 $3=0011_2$ 的页码为 $p=00_2=0$ 页偏移为 $d=11_2=3$。根据页表，可以查到页码 $0$ 对应帧 $5$，因此，逻辑地址 $3$ 映射到物理地址 $23 [= (5 \times 4) + 3]$
- 逻辑地址 $4=0100_2$ 的页码为 $p=01_2=1$ 页偏移为 $d=00_2=0$。根据页表，可以查到页码 $1$ 对应帧 $6$，因此，逻辑地址 $4$ 映射到物理地址 $24 [= (6 \times 4) + 0]$

通常，对于 $32$ 位的 CPU，每个页表条目是 $4$ 字节长($32$位)的，但是这个大小也可能改变。一个 $32$ 位的条目可以指向 $2^{32}$ 个物理帧中的任一个。 如果帧为 $4KB (2^{12})$，那么具有 $32$ 位系统可以访问 $2^{44}$ 字节大小(或 $16TB$)的 **物理内存**

> [!tip] 
> 
> 这里我们应该注意到，分页内存系统的 **物理内存的大小** 不同于 **进程的最大逻辑内存的大小**
> 

当进一步探索分页时，我们将引入其他的信息，这个信息应保存在 **页表条目** 中。该信息也减少了可用于帧地址的位数。因此一个具有 $32$ 位页表条目的系统可访问的物理内存可能小于最大值

> [!tip] 
> 
> $32$ 位 CPU 采用 $32$ 位地址，意味着，一个进程的空间只能为 $2^{32}$ 字节($4\ GB$)。因此，**分页允许我们使用的物理内存大于 CPU 地址指针可访问的空间**
> 

当系统进程需要执行时，它将检查该进程的大小(按页来计算)，进程的每页都需要一帧。因此，如果进程需要 $n$ 页，那么内存中至少应有 $n$ 个帧。如果有，那么就可分配给新进程。进程的第一页装入一个已分配的帧，帧码放入进程的页表中。下一页分配给另一帧，其帧码也放入进程的页表中，等等

![[Pasted image 20241028202727.png]]

### 页表硬件

页表的硬件实现有多种方法。最为简单的一种方法是，**将页表作为一组专用的寄存器来实现**。这些寄存器应用高速逻辑电路来构造，以高效地进行分页地址的转换。由于每次访问内存都要经过分页映射，因此效率是一个重要的考虑因素。CPU 分派器在加载其他寄存器时，也需要加载这些寄存器。**当然，加载或修改页表寄存器的指令是特权的，因此只有操作系统才可以修改内存映射表**

如果页表比较小(例如 $256$ 个条目)，那么页表使用寄存器还是令人满意的。但是，大多数现代计算机都允许页表非常大(例如 $100$ 万个条目)。对于这些机器，采用快速寄存器来实现页表就不可行了。因而需要 **将页表放在内存** 中，并将 **页表基地址寄存器**(**PTBR**) 指向页表。改变页表只需要改变这一寄存器就可以，这也大大降低了上下文切换的时间

> [!question] 
> 
> 采用这种方案，访问一个字节需要两次内存访问(一次用于页表条目，一次用于字节)。这样，内存访问的速度就减半。在大多数情况下，这种延迟是无法忍受的。我们还不如采用交换机制!
> 

这个问题的标准解决方案是采用专用的、小的、查找快速的高速硬件缓冲，它称为 **转换表缓冲区**(**TLB**)。 **TLB 是关联的高速内存**。TLB 条目由两部分组成： **键(标签)** 和 **值**

+ 当关联内存根据给定值查找时，它会同时与所有的键进行比较。如果找到条目，那么就得到相应值的字段
+ 搜索速度很快；**现代的 TLB 查找硬件是指令流水线的一部分**，基本上不添加任何性能负担
+ 为了能够在单步的流水线中执行搜索，**TLB 不应大**；通常它的大小在 `32 ~ 1024`之间

如果页码不在 TLB 中(称为 **TLB 未命中**)，那么就需访问页表。取决于 CPU，这可能由硬件自动处理或通过操作系统的中断来处理。当得到帧码后，就可以用它来访问内存

![[Pasted image 20241028203002.png]]

## 页表结构

大多数现代计算机系统支持大逻辑地址空间($2^{32} \sim 2^{64}$)。在这种情况下，页表本身可以非常大。例如，假设具有 $32$ 位逻辑地址空间的一个计算机系统。如果系统的页大小为 $4KB(2^{12})$，那么页表可以多达 $100$ 万的条目($2^{32}/2^{12}$)

假设每个条目有 $4$ 字节，那么每个进程需要 $4\ MB$ 物理地址空间来存储页表本身。显然，我们并不想在内存中连续地分配这个页表。这个问题的一个简单解决方法是将页表划分为更小的块。完成这种划分有多个方法。如下图是一个使用 **两层分页**：页表再分页

![[Pasted image 20241028203727.png]]

> [!tip] 
> 
> 其中 $p_1$ 是用来访问外部页表的索引，而 $p_2$ 是内部页表的页偏移
> 
